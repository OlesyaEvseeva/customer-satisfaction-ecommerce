{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e109ff7",
   "metadata": {},
   "source": [
    "# Data Integration & Preprocessing for Customer Satisfaction Analysis\n",
    "\n",
    "This notebook is part of a larger project exploring customer satisfaction in Brazilian e-commerce using the [Olist dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).  \n",
    "It builds on the cleaned datasets prepared in the previous notebook by joining them into a single analytical table, performing additional data cleaning, and engineering features to support the upcoming analysis.\n",
    "\n",
    "\n",
    "**Goals of this notebook:**\n",
    "\n",
    "- Join the cleaned tables into a consolidated dataset at the order level  \n",
    "- Clean and standardize the merged dataset (e.g., data types, missing values)  \n",
    "- Create new features to capture relevant aspects of orders, products, payments etc.\n",
    "- Export the final dataset for analysis\n",
    "\n",
    "**This notebook is preceded and followed by:**\n",
    "\n",
    "- [Data Cleaning Notebook](./01_data_cleaning.ipynb): loads and prepares the individual raw datasets for integration  \n",
    "- [Exploratory Analysis Notebook](./03_customer-satisfaction-analysis.ipynb): investigates customer satisfaction patterns and key influencing factors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68907a04",
   "metadata": {},
   "source": [
    "## **Data Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98399a",
   "metadata": {},
   "source": [
    "### Load Cleaned CSV Files into DuckDB Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cleaned CSV Files into DuckDB Tables\n",
    "\n",
    "# Path to the folder containing cleaned CSV files\n",
    "data_path = \"..data/cleaned\"\n",
    "\n",
    "# Connect to an in-memory DuckDB database\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "# Load each cleaned dataset into its own DuckDB table\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE customers AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/customers.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE orders AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/orders.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE items AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/items.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE payments AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/payments.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE reviews AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/reviews.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE products AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/products.csv');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TABLE sellers AS \n",
    "    SELECT * FROM read_csv_auto('{data_path}/sellers.csv');\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackfuelpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
