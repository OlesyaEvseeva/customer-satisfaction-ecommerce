{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for better readability in output\n",
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db7b62b",
   "metadata": {},
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f8f36",
   "metadata": {},
   "source": [
    "### Load and explore all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecc7fe",
   "metadata": {},
   "source": [
    "➤ Load all raw CSV files into individual DataFrames and store them in a dictionary for easier handling and quick access during exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files from the Brazilian E-Commerce dataset into separate DataFrames\n",
    "data_path = \"../data/brazilian/raw/\"\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "customers_raw = pd.read_csv(data_path + \"olist_customers_dataset.csv\")\n",
    "geolocation_raw = pd.read_csv(data_path + \"olist_geolocation_dataset.csv\")\n",
    "orders_raw = pd.read_csv(data_path + \"olist_orders_dataset.csv\")\n",
    "items_raw = pd.read_csv(data_path + \"olist_order_items_dataset.csv\")\n",
    "payments_raw = pd.read_csv(data_path + \"olist_order_payments_dataset.csv\")\n",
    "reviews_raw = pd.read_csv(data_path + \"olist_order_reviews_dataset.csv\")\n",
    "products_raw = pd.read_csv(data_path + \"olist_products_dataset.csv\")\n",
    "sellers_raw = pd.read_csv(data_path + \"olist_sellers_dataset.csv\")\n",
    "translation_raw = pd.read_csv(data_path + \"product_category_name_translation.csv\")\n",
    "\n",
    "# Store all DataFrames in a dictionary for easier looping and inspection\n",
    "dataframes_raw = {\n",
    "    \"customers\": customers_raw,\n",
    "    \"geolocation\": geolocation_raw,\n",
    "    \"orders\": orders_raw,\n",
    "    \"items\": items_raw,\n",
    "    \"payments\": payments_raw,\n",
    "    \"reviews\": reviews_raw,\n",
    "    \"products\": products_raw,\n",
    "    \"sellers\": sellers_raw,\n",
    "    \"translation\": translation_raw,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf65185",
   "metadata": {},
   "source": [
    "The following tables are included in the Brazilian E-Commerce dataset:\n",
    "\n",
    "- `customers`: customer information  \n",
    "- `geolocation`: geographical coordinates by zip code prefix  \n",
    "- `orders`: order details including status and timestamps  \n",
    "- `items`: product-level details for each order  \n",
    "- `payments`: payment methods, amounts and installment information \n",
    "- `reviews`: customer reviews and ratings  \n",
    "- `products`: product attributes including category and dimensions\n",
    "- `sellers`: seller information  \n",
    "- `translation`: Portuguese-to-English product category mapping \n",
    "\n",
    "*Note: Original file names such as `olist_customers_dataset.csv` were renamed to simpler identifiers like `customers` for ease of use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab35b00",
   "metadata": {},
   "source": [
    "➤  Summary of all tables using `.shape`, column names, and duplicate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20441cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to summarize a dictionary of DataFrames\n",
    "def summarize_dataframes(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of DataFrames and returns a summary DataFrame\n",
    "        with the following information for each:\n",
    "        - name: the key name from the dictionary\n",
    "        - rows: number of rows in the DataFrame\n",
    "        - columns: number of columns\n",
    "        - column_names: a list of column names\n",
    "        - duplicates: number of duplicated rows\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "\n",
    "    # Loop over each DataFrame in the dictionary\n",
    "    for name, df in df_dict.items():\n",
    "        summary.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"rows\": df.shape[0],\n",
    "                \"columns\": df.shape[1],\n",
    "                \"column_names\": list(df.columns),\n",
    "                \"duplicates\": df.duplicated().sum(),\n",
    "            }\n",
    "        )\n",
    "    # Return a summary DataFrame\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "# Call the function and display the summary of all loaded DataFrames\n",
    "summarize_dataframes(dataframes_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59cac0",
   "metadata": {},
   "source": [
    "➤  Quick sampling of 5 rows from each table for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of 5 rows from each DataFrame for a quick visual inspection\n",
    "for name, df in dataframes_raw.items():\n",
    "    print(f'{name.capitalize()}:')\n",
    "    display(df.sample(5))\n",
    "    print(\"-\"*130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3a074",
   "metadata": {},
   "source": [
    "➤ Column-wise overview including dtypes, missing values, and unique counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview of column properties (dtypes, missing values, uniques) for all DataFrames\n",
    "def overview(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Creates and displays a column-wise overview for each DataFrame in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        df_dict (dict): A dictionary of DataFrames (e.g., {'orders': orders, ...})\n",
    "\n",
    "    Displays:\n",
    "        For each DataFrame:\n",
    "            - Data type\n",
    "            - Non-null count\n",
    "            - Missing value count and percentage\n",
    "            - Missing value percentage\n",
    "            - Number of unique values\n",
    "            - Unique values\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        print(f'{name.capitalize()}:')\n",
    "        summary = pd.DataFrame(\n",
    "                {\n",
    "                    \"dtype\": df.dtypes,\n",
    "                    \"total\": df.count(),\n",
    "                    \"missing_n\": df.isna().sum(),\n",
    "                    \"missing_%\": df.isna().mean() * 100,\n",
    "                    \"uniques_n\": df.nunique(),\n",
    "                    \"uniques\": [df[col].unique() for col in df.columns],\n",
    "                }\n",
    "        )\n",
    "        display(summary)   \n",
    "        print(\"-\"*130)\n",
    "\n",
    "overview(dataframes_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f5dbc",
   "metadata": {},
   "source": [
    "➤ Quick statistical overview of all numeric columns in each raw table to spot any unusual values or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48afe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize basic statistics of all numeric columns for each DataFrame in the dictionary\n",
    "def describe_numeric_columns(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Displays a transposed summary of descriptive statistics (.describe().T)\n",
    "    for all numeric columns in each DataFrame within the given dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    df_dict (dict): A dictionary where keys are table names and values are pandas DataFrames.\n",
    "\n",
    "    Notes:\n",
    "    - If a DataFrame has no numeric columns, a message is printed instead.\n",
    "    - The output includes a visual summary using display() for easier inspection in notebooks.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"{name.capitalize()}:\")\n",
    "        numeric_df = df.select_dtypes(include=\"number\")\n",
    "\n",
    "        if numeric_df.empty:\n",
    "            print(\"No numeric columns to describe.\")\n",
    "        else:\n",
    "            display(numeric_df.describe().T)\n",
    "\n",
    "        print(\"-\" * 130)\n",
    "\n",
    "\n",
    "describe_numeric_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a649ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dbdiagram.io-compatible table definitions from DataFrames\n",
    "def generate_er_schema(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Generate table definitions in dbdiagram.io format from a dictionary of DataFrames.\n",
    "\n",
    "    For each DataFrame:\n",
    "    - Converts pandas dtypes to SQL-style types (int, varchar, decimal, timestamp, etc.)\n",
    "    - Outputs formatted table definitions ready to paste into dbdiagram.io\n",
    "\n",
    "    Parameters:\n",
    "    df_dict (dict): A dictionary where keys are table names and values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    None (prints output to console)\n",
    "    \"\"\"\n",
    "\n",
    "    dtype_map = {\n",
    "        \"int64\": \"int\",\n",
    "        \"float64\": \"decimal\",\n",
    "        \"object\": \"varchar\",\n",
    "        \"bool\": \"boolean\",\n",
    "        \"datetime64[ns]\": \"timestamp\",\n",
    "    }\n",
    "\n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"Table {name} {{\")\n",
    "        for col in df.columns:\n",
    "            dtype = str(df[col].dtype)\n",
    "            sql_type = dtype_map.get(dtype, \"varchar\")  # fallback to varchar if unknown\n",
    "            print(f\"  {col} {sql_type}\")\n",
    "        print(\"}\\n\")\n",
    "\n",
    "generate_er_schema(dataframes_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d9ce0",
   "metadata": {},
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7241a32",
   "metadata": {},
   "source": [
    "➤ Copy raw DataFrames into a new working dictionary to preserve the original data before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary with copies of all raw DataFrames\n",
    "def copy_raw_dataframes(raw_dict, exclude=None):\n",
    "    \"\"\"\n",
    "    Creates copies of raw DataFrames to preserve the original data before any cleaning steps.\n",
    "\n",
    "    Parameters:\n",
    "        raw_dict (dict): Dictionary containing raw DataFrames.\n",
    "        exclude (list): List of table names to exclude from copying.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with copies of the DataFrames.\n",
    "    \"\"\"\n",
    "    exclude = exclude or []\n",
    "    copy_dict = {}\n",
    "\n",
    "    for name, df in raw_dict.items():\n",
    "        if name in exclude:\n",
    "            continue\n",
    "        copy_dict[name] = df.copy()\n",
    "\n",
    "    return copy_dict\n",
    "\n",
    "\n",
    "dataframes = copy_raw_dataframes(dataframes_raw, exclude=[\"geolocation\"])  # exclude 'geolocation', which is not used in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f646382",
   "metadata": {},
   "source": [
    "➤ Dropping unnecessary columns "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackfuelpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
