{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for better readability in output\n",
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db7b62b",
   "metadata": {},
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f8f36",
   "metadata": {},
   "source": [
    "### Load and explore all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecc7fe",
   "metadata": {},
   "source": [
    "➤ Load all raw CSV files into individual DataFrames and store them in a dictionary for easier handling and quick access during exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files from the Brazilian E-Commerce dataset into separate DataFrames\n",
    "data_path = \"../data/brazilian/raw/\"\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "customers_raw = pd.read_csv(data_path + \"olist_customers_dataset.csv\")\n",
    "geolocation_raw = pd.read_csv(data_path + \"olist_geolocation_dataset.csv\")\n",
    "orders_raw = pd.read_csv(data_path + \"olist_orders_dataset.csv\")\n",
    "items_raw = pd.read_csv(data_path + \"olist_order_items_dataset.csv\")\n",
    "payments_raw = pd.read_csv(data_path + \"olist_order_payments_dataset.csv\")\n",
    "reviews_raw = pd.read_csv(data_path + \"olist_order_reviews_dataset.csv\")\n",
    "products_raw = pd.read_csv(data_path + \"olist_products_dataset.csv\")\n",
    "sellers_raw = pd.read_csv(data_path + \"olist_sellers_dataset.csv\")\n",
    "translation_raw = pd.read_csv(data_path + \"product_category_name_translation.csv\")\n",
    "\n",
    "# Store all DataFrames in a dictionary for easier looping and inspection\n",
    "dataframes_raw = {\n",
    "    \"customers\": customers_raw,\n",
    "    \"geolocation\": geolocation_raw,\n",
    "    \"orders\": orders_raw,\n",
    "    \"items\": items_raw,\n",
    "    \"payments\": payments_raw,\n",
    "    \"reviews\": reviews_raw,\n",
    "    \"products\": products_raw,\n",
    "    \"sellers\": sellers_raw,\n",
    "    \"translation\": translation_raw,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf65185",
   "metadata": {},
   "source": [
    "The following tables are included in the Brazilian E-Commerce dataset:\n",
    "\n",
    "- `customers`: customer information  \n",
    "- `geolocation`: geographical coordinates by zip code prefix  \n",
    "- `orders`: order details including status and timestamps  \n",
    "- `items`: product-level details for each order  \n",
    "- `payments`: payment methods, amounts and installment information \n",
    "- `reviews`: customer reviews and ratings  \n",
    "- `products`: product attributes including category and dimensions\n",
    "- `sellers`: seller information  \n",
    "- `translation`: Portuguese-to-English product category mapping \n",
    "\n",
    "*Note: Original file names such as `olist_customers_dataset.csv` were renamed to simpler identifiers like `customers` for ease of use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab35b00",
   "metadata": {},
   "source": [
    "➤  Summary of all tables using `.shape`, column names, and duplicate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20441cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to summarize a dictionary of DataFrames\n",
    "def summarize_dataframes(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of DataFrames and returns a summary DataFrame\n",
    "        with the following information for each:\n",
    "        - name: the key name from the dictionary\n",
    "        - rows: number of rows in the DataFrame\n",
    "        - columns: number of columns\n",
    "        - column_names: a list of column names\n",
    "        - duplicates: number of duplicated rows\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "\n",
    "    # Loop over each DataFrame in the dictionary\n",
    "    for name, df in df_dict.items():\n",
    "        summary.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"rows\": df.shape[0],\n",
    "                \"columns\": df.shape[1],\n",
    "                \"column_names\": list(df.columns),\n",
    "                \"duplicates\": df.duplicated().sum(),\n",
    "            }\n",
    "        )\n",
    "    # Return a summary DataFrame\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "# Call the function and display the summary of all loaded DataFrames\n",
    "summarize_dataframes(dataframes_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59cac0",
   "metadata": {},
   "source": [
    "➤  Quick sampling of 5 rows from each table for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of 5 rows from each DataFrame for a quick visual inspection\n",
    "for name, df in dataframes_raw.items():\n",
    "    print(f'{name.capitalize()}:')\n",
    "    display(df.sample(5))\n",
    "    print(\"-\"*130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3a074",
   "metadata": {},
   "source": [
    "➤ Column-wise overview including dtypes, missing values, and unique counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview of column properties (dtypes, missing values, uniques) for all DataFrames\n",
    "def overview(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Creates and displays a column-wise overview for each DataFrame in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        df_dict (dict): A dictionary of DataFrames (e.g., {'orders': orders, ...})\n",
    "\n",
    "    Displays:\n",
    "        For each DataFrame:\n",
    "            - Data type\n",
    "            - Non-null count\n",
    "            - Missing value count and percentage\n",
    "            - Missing value percentage\n",
    "            - Number of unique values\n",
    "            - Unique values\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        print(f'{name.capitalize()}:')\n",
    "        summary = pd.DataFrame(\n",
    "                {\n",
    "                    \"dtype\": df.dtypes,\n",
    "                    \"total\": df.count(),\n",
    "                    \"missing_n\": df.isna().sum(),\n",
    "                    \"missing_%\": df.isna().mean() * 100,\n",
    "                    \"uniques_n\": df.nunique(),\n",
    "                    \"uniques\": [df[col].unique() for col in df.columns],\n",
    "                }\n",
    "        )\n",
    "        display(summary)   \n",
    "        print(\"-\"*130)\n",
    "\n",
    "overview(dataframes_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f5dbc",
   "metadata": {},
   "source": [
    "➤ Quick statistical overview of all numeric columns in each raw table to spot any unusual values or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48afe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize basic statistics of all numeric columns for each DataFrame in the dictionary\n",
    "def describe_numeric_columns(df_dict=dataframes_raw):\n",
    "    \"\"\"\n",
    "    Displays a transposed summary of descriptive statistics (.describe().T)\n",
    "    for all numeric columns in each DataFrame within the given dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    df_dict (dict): A dictionary where keys are table names and values are pandas DataFrames.\n",
    "\n",
    "    Notes:\n",
    "    - If a DataFrame has no numeric columns, a message is printed instead.\n",
    "    - The output includes a visual summary using display() for easier inspection in notebooks.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        print(f\"{name.capitalize()}:\")\n",
    "        numeric_df = df.select_dtypes(include=\"number\")\n",
    "\n",
    "        if numeric_df.empty:\n",
    "            print(\"No numeric columns to describe.\")\n",
    "        else:\n",
    "            display(numeric_df.describe().T)\n",
    "\n",
    "        print(\"-\" * 130)\n",
    "\n",
    "\n",
    "describe_numeric_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d9ce0",
   "metadata": {},
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7241a32",
   "metadata": {},
   "source": [
    "➤ Copy raw DataFrames into a new working dictionary to preserve the original data before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary with copies of all raw DataFrames\n",
    "def copy_raw_dataframes(raw_dict, exclude=None):\n",
    "    \"\"\"\n",
    "    Creates copies of raw DataFrames to preserve the original data before any cleaning steps.\n",
    "\n",
    "    Parameters:\n",
    "        raw_dict (dict): Dictionary containing raw DataFrames.\n",
    "        exclude (list): List of table names to exclude from copying.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with copies of the DataFrames.\n",
    "    \"\"\"\n",
    "    exclude = exclude or []\n",
    "    copy_dict = {}\n",
    "\n",
    "    for name, df in raw_dict.items():\n",
    "        if name in exclude:\n",
    "            continue\n",
    "        copy_dict[name] = df.copy()\n",
    "\n",
    "    return copy_dict\n",
    "\n",
    "\n",
    "dataframes = copy_raw_dataframes(dataframes_raw, exclude=[\"geolocation\"])  # exclude 'geolocation', which is not used in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f646382",
   "metadata": {},
   "source": [
    "➤ Dropping unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to be dropped from specific DataFrames based on project scope\n",
    "dropping_columns_dict = {\n",
    "    \"customers\": \"customer_zip_code_prefix\",\n",
    "    \"reviews\": [\"review_comment_title\", \"review_comment_message\"],\n",
    "    \"products\": [\n",
    "        \"product_weight_g\",\n",
    "        \"product_length_cm\",\n",
    "        \"product_height_cm\",\n",
    "        \"product_width_cm\",\n",
    "    ],\n",
    "    \"sellers\": \"seller_zip_code_prefix\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop predefined columns from each DataFrame based on a dictionary mapping\n",
    "def drop_columns(df_dict, drop_dict):\n",
    "    \"\"\"\n",
    "    Drops specified columns from DataFrames within a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        df_dict (dict): Dictionary of DataFrames to be modified.\n",
    "        drop_dict (dict): Dictionary mapping DataFrame names to the columns\n",
    "                          that should be dropped (single string or list of strings).\n",
    "\n",
    "    Modifies:\n",
    "        The DataFrames in df_dict are updated in-place with the specified columns removed.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        if name not in drop_dict:\n",
    "            continue\n",
    "\n",
    "        # Ensure drop_dict[name] is a list, even if a single column is provided\n",
    "        cols_to_drop = drop_dict[name]\n",
    "        if isinstance(cols_to_drop, str):\n",
    "            cols_to_drop = [cols_to_drop]\n",
    "\n",
    "        # Drop columns that exist in the current DataFrame\n",
    "        for col in cols_to_drop:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=col, inplace=True)\n",
    "\n",
    "drop_columns(dataframes, dropping_columns_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914b776",
   "metadata": {},
   "source": [
    "➤ Converting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired data types for specific columns in each DataFrame\n",
    "# Used later to optimize memory and ensure correct formats (e.g., datetime, category)\n",
    "dtype_conversion_dict = {\n",
    "    \"customers\": {\"customer_city\": \"category\", \"customer_state\": \"category\"},\n",
    "    \"orders\": {\n",
    "        \"order_status\": \"category\",\n",
    "        \"order_purchase_timestamp\": \"datetime64[ns]\",\n",
    "        \"order_approved_at\": \"datetime64[ns]\",\n",
    "        \"order_delivered_carrier_date\": \"datetime64[ns]\",\n",
    "        \"order_delivered_customer_date\": \"datetime64[ns]\",\n",
    "        \"order_estimated_delivery_date\": \"datetime64[ns]\",\n",
    "    },\n",
    "    \"items\": {\"shipping_limit_date\": \"datetime64[ns]\"},\n",
    "    \"payments\": {\"payment_type\": \"category\"},\n",
    "    \"reviews\": {\n",
    "        \"review_score\": \"category\",\n",
    "        \"review_creation_date\": \"datetime64[ns]\",\n",
    "        \"review_answer_timestamp\": \"datetime64[ns]\",\n",
    "    },\n",
    "    \"sellers\": {\"seller_city\": \"category\", \"seller_state\": \"category\"},\n",
    "    \"products\": {\"product_category_name\": \"category\"},\n",
    "    \"translation\": {\n",
    "        \"product_category_name\": \"category\",\n",
    "        \"product_category_name_english\": \"category\",\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9727e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column data types for each DataFrame based on a predefined mapping\n",
    "def apply_dtypes_conversions(df_dict, conversion_dict):\n",
    "    \"\"\"\n",
    "    Applies data type conversions to specific columns in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "        df_dict (dict): A dictionary where keys are table names and values are pandas DataFrames.\n",
    "        conversion_dict (dict): A nested dictionary specifying columns and their target data types\n",
    "                                for each corresponding DataFrame.\n",
    "\n",
    "    Notes:\n",
    "    - This function modifies the DataFrames in place.\n",
    "    - Useful for memory optimization (e.g., converting to 'category') and for parsing dates properly.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        if name not in conversion_dict:\n",
    "            continue  # skip DataFrames not listed in the conversion dictionary\n",
    "\n",
    "        for col, dtype in conversion_dict[name].items():\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(dtype)\n",
    "\n",
    "apply_dtypes_conversions(dataframes, dtype_conversion_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stackfuelpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
